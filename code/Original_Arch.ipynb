{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOi7+CGJkVjI9wUHd7uP+1a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Correct Code"],"metadata":{"id":"vo0TPW7sYcvM"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Layer\n","import tensorflow.keras as K\n","import tensorflow.keras.backend as Kback\n","\n","def SAM_avg(x, cam):\n","    print(\"---\")\n","    batch, _, _, channel = x.shape\n","    print(\"SAM_avg!!! Input Shape:\", x.shape)\n","    x = K.layers.SeparableConv2D(channel, kernel_size=1, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal())(x)\n","    print(\"SepConv2D_1 shape:\", x.shape)\n","    x = K.layers.SeparableConv2D(channel, kernel_size=3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal())(x)\n","    print(\"SepConv2D_2 shape:\", x.shape)\n","    x = K.layers.BatchNormalization()(x)\n","    print(\"BN shape:\", x.shape)\n","    x = x*cam\n","    print(\"X*CAM:\", x.shape)\n","\n","    ## Average Pooling\n","    x1 = tf.reduce_mean(x, axis=-1)\n","    print(\"MEAN:\", x1.shape)\n","    x1 = tf.expand_dims(x1, axis=-1)\n","    print(\"Expand:\", x1.shape)\n","\n","    ## Conv layer\n","    feats = K.layers.Conv2D(1, kernel_size=7, padding=\"same\", activation=\"sigmoid\", kernel_initializer=tf.keras.initializers.HeNormal())(x1)\n","    print(\"Conv2D shape:\", feats.shape)\n","    feats = K.layers.Multiply()([x, feats])\n","    print(\"Out shape:\", feats.shape)\n","    return feats\n","\n","def SAM_max(x, cam):\n","    batch, _, _, channel = x.shape\n","    print(\"---\")\n","    print(\"SAM_max!!! Input Shape:\", x.shape)\n","    x = K.layers.SeparableConv2D(channel, kernel_size=1, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal())(x)\n","    print(\"SepConv2D_1 shape:\", x.shape)\n","    x = K.layers.SeparableConv2D(channel, kernel_size=3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal())(x)\n","    print(\"SepConv2D_2 shape:\", x.shape)\n","    x = K.layers.BatchNormalization()(x)\n","    print(\"BN shape:\", x.shape)\n","    x = x*cam\n","    print(\"X*CAM:\", x.shape)\n","\n","    ## Max Pooling\n","    x2 = tf.reduce_max(x, axis=-1)\n","    print(\"MAX:\", x2.shape)\n","    x2 = tf.expand_dims(x2, axis=-1)\n","    print(\"Expand:\", x2.shape)\n","\n","    ## Conv layer\n","    feats = K.layers.Conv2D(1, kernel_size=7, padding=\"same\", activation=\"sigmoid\")(x2)\n","    print(\"Conv2D shape:\", feats.shape)\n","    feats = K.layers.Multiply()([x, feats])\n","    print(\"Out shape:\", feats.shape)\n","    return feats\n","\n","def CAM(x, ratio=8):\n","    batch, _, _, channel = x.shape\n","    print(\"CAM!!! Input Shape:\", x.shape)\n","    ## Shared layers\n","    l1 = K.layers.Dense(channel//ratio, activation=\"relu\", use_bias=False)\n","    l2 = K.layers.Dense(channel, use_bias=False)\n","    ## Global Average Pooling\n","    x1 = K.layers.GlobalAveragePooling2D()(x)\n","    print(\"GAP shape:\", x1.shape)\n","    x1 = l1(x1)\n","    print(\"GAP + Dense shape:\", x1.shape)\n","    x1 = l2(x1)\n","    print(\"GAP + Dense + Dense shape:\", x1.shape)\n","    ## Global Max Pooling\n","    x2 = K.layers.GlobalMaxPooling2D()(x)\n","    print(\"GMP shape:\", x2.shape)\n","    x2 = l1(x2)\n","    print(\"GMP + Dense shape:\", x2.shape)\n","    x2 = l2(x2)\n","    print(\"GMP + Dense + Dense shape:\", x2.shape)\n","    ## Add both the features and pass through sigmoid\n","    feats = x1 + x2\n","    feats = K.layers.Activation(\"sigmoid\")(feats)\n","    feats = K.layers.Multiply()([x, feats])\n","    print(\"Out shape:\", feats.shape)\n","    return feats\n","\n","class ChannelDropout(K.layers.Layer):\n","    def __init__(self, drop_ratio=0.2):\n","        super(ChannelDropout, self).__init__()\n","        self.drop_ratio = drop_ratio\n","\n","    def build(self, input_shape):\n","        _, _, _, self.channels = input_shape\n","        # Initialize a trainable mask with ones\n","        self.mask = RichardsSigmoid(units=1)(self.add_weight(\"mask\", shape=(1, 1, 1, self.channels), initializer=\"ones\", trainable=True))\n","\n","    def call(self, x):\n","        # Duplicate the mask to match the batch size\n","        mask = tf.tile(self.mask, [tf.shape(x)[0], 1, 1, 1])\n","        # Multiply the input by the mask\n","        x = x * mask\n","        #num_channels_to_keep = int(self.channels // 1.25) # WHY THEY DO NOT USE THE RATIO????!!!!\n","        num_channels_to_keep = int(x.shape[3] * (1 - self.drop_ratio)) # THIS IS OUR FORMULA\n","        sorted_x, indices = tf.nn.top_k(x, k=num_channels_to_keep, sorted=True)\n","        sorted_x = sorted_x[:,:,:,0:num_channels_to_keep]\n","        return sorted_x\n","\n","class RichardsSigmoid(K.layers.Layer):\n","    def __init__(self, units=1, **kwargs):\n","        super(RichardsSigmoid, self).__init__(**kwargs)\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        # Initialize learnable parameters: A, Q, mu\n","        self.A = self.add_weight(name='A', shape=(self.units,), initializer='uniform', trainable=True)\n","        self.Q = self.add_weight(name='Q', shape=(self.units,), initializer='uniform', trainable=True)\n","        self.mu = self.add_weight(name='mu', shape=(self.units,), initializer='uniform', trainable=True)\n","\n","        super(RichardsSigmoid, self).build(input_shape)\n","\n","    def call(self, x):\n","        # Richards sigmoid function\n","        return 1 / (1 + tf.exp(-self.A * tf.exp(-self.Q * (x - self.mu))))\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[:-1] + (self.units,)\n","\n","def CSSAM(x, cam):\n","    print(\"---\")\n","    print(\"CSSAM!!! Input Shape:\", x.shape)\n","    x_avg = SAM_avg(x, cam)\n","    print(\"CSSAM!!! SAM_AVG shape:\", x_avg.shape)\n","    x_max = SAM_max(x, cam)\n","    print(\"CSSAM!!! SAM_MAX shape:\", x_max.shape)\n","    x = K.layers.Concatenate()([x_avg, x_max, cam])\n","    print(\"CSSAM!!! Concat shape:\", x.shape)\n","    x = ChannelDropout(drop_ratio=0.5)(x)\n","    print(\"CSSAM!!! Channel Dropout shape:\", x.shape)\n","    return x\n","\n","def main():\n","      # Esempio di input con dimensioni (1, 8, 8, 1024)\n","      input_tensor = tf.random.normal([1, 8, 8, 1024])\n","\n","      # CAM\n","      output_cam = CAM(input_tensor)\n","\n","      # Test CSSAM\n","      output_cssam = CSSAM(input_tensor, output_cam)\n","\n","if __name__ == \"__main__\":\n","        main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wtLjwmSpJp4p","executionInfo":{"status":"ok","timestamp":1720289005088,"user_tz":-120,"elapsed":810,"user":{"displayName":"Massimo Romano","userId":"04267578953418415513"}},"outputId":"b4b898c7-e496-4234-f161-c7e47237d8e4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["CAM!!! Input Shape: (1, 8, 8, 1024)\n","GAP shape: (1, 1024)\n","GAP + Dense shape: (1, 128)\n","GAP + Dense + Dense shape: (1, 1024)\n","GMP shape: (1, 1024)\n","GMP + Dense shape: (1, 128)\n","GMP + Dense + Dense shape: (1, 1024)\n","Out shape: (1, 8, 8, 1024)\n","---\n","CSSAM!!! Input Shape: (1, 8, 8, 1024)\n","---\n","SAM_avg!!! Input Shape: (1, 8, 8, 1024)\n","SepConv2D_1 shape: (1, 8, 8, 1024)\n","SepConv2D_2 shape: (1, 8, 8, 1024)\n","BN shape: (1, 8, 8, 1024)\n","X*CAM: (1, 8, 8, 1024)\n","MEAN: (1, 8, 8)\n","Expand: (1, 8, 8, 1)\n","Conv2D shape: (1, 8, 8, 1)\n","Out shape: (1, 8, 8, 1024)\n","CSSAM!!! SAM_AVG shape: (1, 8, 8, 1024)\n","---\n","SAM_max!!! Input Shape: (1, 8, 8, 1024)\n","SepConv2D_1 shape: (1, 8, 8, 1024)\n","SepConv2D_2 shape: (1, 8, 8, 1024)\n","BN shape: (1, 8, 8, 1024)\n","X*CAM: (1, 8, 8, 1024)\n","MAX: (1, 8, 8)\n","Expand: (1, 8, 8, 1)\n","Conv2D shape: (1, 8, 8, 1)\n","Out shape: (1, 8, 8, 1024)\n","CSSAM!!! SAM_MAX shape: (1, 8, 8, 1024)\n","CSSAM!!! Concat shape: (1, 8, 8, 3072)\n","CSSAM!!! Channel Dropout shape: (1, 8, 8, 1536)\n"]}]},{"cell_type":"markdown","source":["\n","\n","\n","```\n","input tensor: torch.Size([1, 1024, 8, 8])\n","---\n","CAM\n","GAP: torch.Size([1, 1024])\n","GAP + Dense: torch.Size([1, 128])\n","GAP + Dense + Dense: torch.Size([1, 1024])\n","GMP: torch.Size([1, 1024, 1, 1])\n","GMP + Dense: torch.Size([1, 128])\n","GMP + Dense + Dense: torch.Size([1, 1024])\n","Feats shape: torch.Size([1, 1024])\n","Output shape: torch.Size([1, 1024, 8, 8])\n","Output shape after CAM: torch.Size([1, 1024, 8, 8])\n","---\n","SAM_AVG\n","Input shape: torch.Size([1, 1024, 8, 8])\n","SepConv2d_1 shape: torch.Size([1, 1024, 8, 8])\n","SepConv2d_2 shape: torch.Size([1, 1024, 8, 8])\n","BatchNorm2d shape: torch.Size([1, 1024, 8, 8])\n","X*CAM shape: torch.Size([1, 1024, 8, 8])\n","Mean pooling shape: torch.Size([1, 1, 8, 8])\n","Conv2d shape: torch.Size([1, 1, 8, 8])\n","Sigmoid: torch.Size([1, 1, 8, 8])\n","Output shape:: torch.Size([1, 1024, 8, 8])\n","---\n","SAM_MAX\n","SepConv2d_1 shape: torch.Size([1, 1024, 8, 8])\n","SepConv2d_2 shape: torch.Size([1, 1024, 8, 8])\n","BatchNorm2d shape: torch.Size([1, 1024, 8, 8])\n","X*CAM shape: torch.Size([1, 1024, 8, 8])\n","MAX pooling shape: torch.Size([1, 1, 8, 8])\n","Conv2d shape: torch.Size([1, 1, 8, 8])\n","Sigmoid: torch.Size([1, 1, 8, 8])\n","Output shape: torch.Size([1, 1024, 8, 8])\n","Output shape after CSSAM: torch.Size([1, 3072, 8, 8])\n","\n","CSSAM:\n","\n","CSSAM: SAM_avg shape: torch.Size([1, 1024, 8, 8])\n","CSSAM: SAM_max shape: torch.Size([1, 1024, 8, 8])\n","CSSAM: Concatenation shape: torch.Size([1, 3072, 8, 8])\n","CSSAM: Channel Dropout shape: torch.Size([1, 1536, 8, 8])\n","\n","```"],"metadata":{"id":"0s0ymOpByp7G"}}]}